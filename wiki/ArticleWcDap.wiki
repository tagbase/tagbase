#summary Working with Wildlife Computers DAP and GPE software

<wiki:toc max_depth="2" />

= Introduction =

This page shares some of our experiences in working with the software suite of [http://www.wildlifecomputers.com/downloads.aspx Wildlife Computers], and namely DAP and GPE. This only serves as an practical guide to using their software, so you should refer to their documentation or customer service for detailed operations. You should also understand that manufacturers like Wildlife Computers has a rapid update/ release cycle on their software, and it is likely we lag behind in catching up with all their changes. We encourage you leaving us wiki comments at this page to help improve our collective experience in working with the software. Lastly, we are not advocating for any tag manufacturers, but rather we have yet to explore the many other options/ software, most of which are not free or easily accessible over the web. 

= Details =

== Mixed processing of tags/ decoding of Argos messages ==

DAP allows simple drag-and-drop operation of any number of Argos messages (DS files in the form of .txt), Wildlife Computer binary files (.wch), and tag setup files (.htm) from Windows Explorer. One approach to data processing involves saving Argos messages into a folder, and dragging that entire folder to DAP. If you want to apply a filter, via specific PTT IDs (Argos platform transmitter IDs), you will need to click on "Filter" and fill out a form *before* you drag-and-drop. 

http://tagbase.googlecode.com/svn/trunk/images/WcDap1.jpg

"Export Decoded Data" in the "File" menu will allow you to export all the data from multiple tag into a single set of .csv files. This set will be used as inputs for import into Tagbase. Note at this stage, no geolocations are available. 

http://tagbase.googlecode.com/svn/trunk/images/WcDap2.jpg

If you open any one of the many .csv files, you will find "DeployID" and it is essentially the PTT IDs. In the absence of a PTT ID for an archival tag, the tag serial number is used for both "DeployID" and "PTT" data columns. 

== Obtaining manufacturer light-based geolocation estimates via GPE ==

  * Start "Global Position Estimator" from your Windows Start menu (under Wildlife Computers), drag-and-drop a "LightLoc.csv" file or a previously processed GPE file (.wcg2).
  
http://tagbase.googlecode.com/svn/trunk/images/WcGpe1.jpg  
  
  * Or invoke it through the menu bar of DAP Processor (Tag > Light Level Global Position Estimator).
 
http://tagbase.googlecode.com/svn/trunk/images/WcDap3.jpg

  * Select a tag to process or wait until automated processing is completed. Make adjustments where appropriate (you will have to consult Wildlife Computers documentation/ customer service for assistance).
  
  * Save the results, "File" > "Save" as a .wcg2 file to your preferred location for later use

  * Export the results back to a "`LightLoc.csv`" via "File" > "Export results in CSV format"

http://tagbase.googlecode.com/svn/trunk/images/WcGpe2.jpg

== Utilizing Kalman filter/ Trackit interfaces in GPE ==    

  * If you decide to run any *Kalman filter/ Trackit analysis*, proceed to do so via the "File" menu. Save & export after estimation is completed.
  
  * The Kalman filter/ Trackit analysis is powered by open-source libraries authored by Anders Nielsen, Chi Hin Lam and John Sibert, and provided by the [http://www.soest.hawaii.edu/PFRP/ Pelagic Fisheries Research Program]. 
  
  * We recommend the following papers and references therein for a more complete understanding of the methods and assumptions needed to best utilize this type of analysis.
  
  # [http://www.int-res.com/abstracts/meps/v419/p71-84/ Trackit] - Lam, Chi H., Anders Nielsen, and John R. Sibert, 2010. Incorporating sea-surface temperature to the light-based geolocation model !TrackIt. Marine Ecology Progress Series MEPS 419:71-84
  # [http://www.soest.hawaii.edu/PFRP/reprints/lam_nielsen_sibert.pdf Ukfsst] - Lam, Chi H., Anders Nielsen, and John R. Sibert, 2008. Improving light and temperature based geolocation by unscented Kalman filtering. Fisheries Research, 91: 15-25
  # [http://www.soest.hawaii.edu/PFRP/reprints/sibert_horizontal.pdf Kftrack] Sibert, J.R., Musyl, M.K., Brill, R.W., 2003. Horizontal movements of bigeye tuna (Thunnus obesus) near Hawaii determined by Kalman filter analysis of archival tagging data. Fisheries Oceanography, 12(3):141-151.
  
  
== Importing multiple tags from DAP into Tagbase ==

{{{ 
Bugs found -
We notice a bug in Wildlife Computers DAP software (3.0.69, last tested) that when 
you process 2 or more archival tags (.wch) together, the resultant DAP -Archive.csv output 
will only contain data from 1 of the tags you are processing. Please stick with Strategy 1 
for now if you are using DAP to process multiple archival tags. 
}}}

  * "DeployID" in a DAP .csv file will match up with `TagPTTID` in a batch import job file (e.g _!TagbaseBatchJob.xls_) to establish a link between the data in a DAP .csv file and the information provided in the job file.
  
  * Therefore, as mentioned above, for an archival tag, you should enter the tag serial number in both `TagCode` and `TagPTTID`.
  
http://tagbase.googlecode.com/svn/trunk/images/ImportJob4.jpg

  * The Wildlife Computers DAP processing workflow has changed between different releases of DAP versions (2 & 3). At any point in time, you *should keep only 1 most-updated copy* of the "`LightLoc.csv`" file for each tag, especially when you perform any geolocation processing with GPE.
 
{{{ 
Tips -
We recommend using Strategy 1 as your preferred workflow in processing DAP data. 
The reason is that you will have an easier time keeping track of your files for each tag, 
rather than having to sort through the data-dump from DAP and figure out the missing data 
pieces. A common case for missing data pieces is when a tag only partially reported its data. 
If that happens, you are likely not getting the full suite of DAP .csv outputs. 
}}}
  
  * Use the following table to guide you in setting up a [ArticleImport#Step_1_-_Setting_up_the_batch_job_file_from_the_Excel_template batch import job file] (e.g _!TagbaseBatchJob.xls_). Consider the following scenario: you are processing 3 tags, Tag 1 through 3. 
  
|| *Strategy* || *Workflow in DAP* || *Any Geolocation Processing with GPE?* || *File Organization* || *Batch import job file (e.g _!TagbaseBatchJob.xls_) entry* || *Example Screenshot* ||
||1.|| 1 tag at a time, with organized Argo messages e.g. `ArgosDS-Tag1.txt`... `ArgosDS-Tag3.txt`. Tag setup files (.htm) are also included || Yes; with updated `Tag1-LightLoc.csv`... `Tag3-LightLoc.csv` || Each tag has its own folder, and updated `LightLoc.csv` files overwrite original DAP output || 3 entries from `Tag1*.csv` ... `Tag3*.csv` || [http://tagbase.googlecode.com/svn/trunk/images/WcDapA.jpg Screenshot A] ||
||2.|| All tags in 1 file with merged Argo messages e.g. `ArgosDS-AllTags.txt`. Tag setup files (.htm) are also included || Yes; same as above || One set of DAP outputs  in a folder, along with 3 `LightLoc.csv` files || 3 entries for `AllTags*.csv` + 3 entries for `Tag1-LightLoc.csv`... `Tag3-LightLoc.csv` || [http://tagbase.googlecode.com/svn/trunk/images/WcDapB.jpg Screenshot B] ||

{{{ 
Important!!! -
Behind the scene of Strategy 2, Tagbase creates separate folders, according to the 
distinct DeployIDs found in WC DAP .csv output files. Tagbase then allocates the data pieces 
to the right files inside the folders, resulting in a set of DAP output files in each folder. 
Tagbase does not delete the contents of folders beforehand, so you will have to delete all 
contents or remove existing DAP files/ folder, as Tagbase will append to existing files 
during the import, leading to duplicating data records. 
}}}

 * Screenshot A
 
 http://tagbase.googlecode.com/svn/trunk/images/WcDapA.jpg
 
 * Screenshot B
 
 http://tagbase.googlecode.com/svn/trunk/images/WcDapB.jpg

 * Remember, for the time-at-depth or time-at-temperature data to display properly, you will need to supply all your setup .htm files as well. Or you specify the `BinSampleInterval`, `BinID_Depth` and `BinID_Temperature` for each new tag to import. See *[ArticleImport#for_Wildlife_Computers_PAT_tags_(Orange) here]* for details.